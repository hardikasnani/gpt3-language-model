{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5af6411",
      "metadata": {
        "id": "c5af6411"
      },
      "source": [
        "Tasks:\n",
        "#### 1. Data preparation\n",
        "\n",
        "- Download a translation dataset (pick a language pair) from https://www.manythings.org/anki/\n",
        "\n",
        "\n",
        "\n",
        "- Alternatively, if you prefer, download morphological segmentation data from http://turing.iimas.unam.mx/wix/static/resources/language_data.tar.bz2. You can choose which language you want to work with or even try combining them. This dataset will likely be a bit faster to train than the MT one above. Also, one trick that has been shown to work on this type of data is to add in random strings that map to themselves, in order to teach the decoder to output mostly the same characters as it sees in the input (with the addition of the morpheme boundary characters).\n",
        "\n",
        "\n",
        "\n",
        "- Create three .tsv files, one for each of train/dev/test partitions (if you use the MT data you will need to choose how to split the data, probably something like 70%/15%/15% would work). Once you have the data in this format, you smiply need to update the code in the \"Load Data\" section to load your data.\n",
        "\n",
        "\n",
        "- For the NMT dataset, you may need to update the tokenization function depending on your language(s).\n",
        "\n",
        "\n",
        "#### 2. Compare RNN Decoder (`Decoder` in the code) vs. RNN Decoder with Attention (`AttentionDecoder` in the code) \n",
        "- Read through the code for the Encoder, Attention, and the two Decoder classes. Make sure you have some understanding of what is going on before preceding.\n",
        "\n",
        "- Train model (for ~50-100 epochs? more if time permits...) using the \"Vanilla Decoder\", which is the default.\n",
        "\n",
        "\n",
        "- Make the necessary changes to the code (there should only be 2, there places are marked with a \"TODO\" comment) in order to run the same experiment with The AttentionDecoder.\n",
        "\n",
        "\n",
        "- Compare the results (eg the validation loss). Do you notice any difference? For now, just look at the validation loss.\n",
        "\n",
        "\n",
        "- Add to the `evaluate` function so that you also report a metric (you choose what metric). Alternatively for an easier task, complete the bleu-score function towards the end of the notebook.\n",
        "\n",
        "\n",
        "#### 3. (Bonus 1) Implement Teacher Forcing\n",
        "- Currently, in the `Seq2Seq` class's `forward()` method, there is a parameter called `teacher_forcing_ratio`, but we don't use it. \"Teacher forcing\" is a technique for training seq2seq models where, at each timestep, you give the decoder the correct output from the previous time step with some probability (instead of always feeding it the prediction from the previous time step, which might be wrong). Implement teacher forcing in this method. Assume `teacher_forcing_ratio` is a float between 0 and 1, and indicates the proportion of time we give the correct input to the decoder.\n",
        "\n",
        "#### 4. (Bonus 2: pobably more relevant for the morphological segmentation corpus) Compare with RNN Transducer\n",
        "- Train an RNN Transducer (from a few weeks ago) on the same data and compare the performances. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Us3Dn2sWQPal",
      "metadata": {
        "id": "Us3Dn2sWQPal"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### NOTES:\n",
        "\n",
        "To begin with...\n",
        "\n",
        "1. If there is any import Error for Fields from torchtext.data, we would then need specific version of torchtext (0.8), please pip install requirements.txt which is present.\n",
        "\n",
        "To pip install from colab notebook cell-\n",
        "\n",
        "```\n",
        "!pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "\n",
        "2. ENG-DEU file download and train, val, test file creation-\n",
        "\n",
        "```\n",
        "!python eng_german_sample_download.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SLA3dpG-ZHNW",
      "metadata": {
        "id": "SLA3dpG-ZHNW"
      },
      "source": [
        "If there is OSError: ... so: undefined symbol: ... , please re-execute the cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.8.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ3_de1vKDUt",
        "outputId": "269c5bf1-05f9-4f0b-f570-e3c408f4cd13"
      },
      "id": "kZ3_de1vKDUt",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 19.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eng_german_sample_download.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrbV3rS1OXzM",
        "outputId": "eb049d44-f28a-44b6-9b96-eeb8146c81b3"
      },
      "id": "PrbV3rS1OXzM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'eng_german_sample_download.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9cff514f",
      "metadata": {
        "id": "9cff514f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de7ee264",
      "metadata": {
        "id": "de7ee264"
      },
      "source": [
        "## Load Data\n",
        "We will use utilities from the Pytorch package \"torchtext\" to easily load the data and batch it using buckets according to length (in order to minimize padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9399f959",
      "metadata": {
        "id": "9399f959",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a0990a-00a8-4f0b-eb81-743728b83b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "char_tokenize = lambda s: s.split()\n",
        "SRC = Field(tokenize=char_tokenize, init_token='<sow>', eos_token='<eow>', lower=True)\n",
        "TGT = Field(tokenize=char_tokenize, init_token='<sow>', eos_token='<eow>', lower=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whO99XOEPZ5N",
        "outputId": "eab38ae9-8cb0-471b-c50d-3fac2831574a"
      },
      "id": "whO99XOEPZ5N",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls \"/content/drive/MyDrive/IUB Fall 22/Advance NLP/Practicals/hindi_data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXkK179mPl6h",
        "outputId": "0582b396-2ba3-4e31-ff75-de139820bf39"
      },
      "id": "wXkK179mPl6h",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.tsv  train.tsv  val.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/IUB Fall 22/Advance NLP/Practicals/hindi_data/\""
      ],
      "metadata": {
        "id": "FlWD9TFJPf9J"
      },
      "id": "FlWD9TFJPf9J",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e3e75ad3",
      "metadata": {
        "id": "e3e75ad3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcce45a-0e28-4c4c-91a6-24fa0b2ce986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# TODO: Update this cell to load the dataset you chose. Once you have your data in 3 tsv \n",
        "# files (one per train/dev/test), just update the path and the names of the files.\n",
        "#\n",
        "path_to_data = file_path # <give your data folder location here.>\n",
        "\n",
        "train_data, val_data, test_data = TabularDataset.splits(\n",
        "        path=path_to_data, train='train.tsv', # <your train.tsv file here>\n",
        "        validation='val.tsv', # <your val.tsv file here>\n",
        "        test='test.tsv', # <your test.tsv file here>\n",
        "        format='tsv',\n",
        "        fields=[('src', SRC), ('tgt', TGT)])\n",
        "\n",
        "# If your dataset is huge and contains many unique words, then for the sake of fast execution, you can add this argument: min_freq = <some integer>\n",
        "# Only tokens that appear atleast <some integer> times then are considered. Other such words are replaced by < UNK >\n",
        "\n",
        "SRC.build_vocab(train_data)\n",
        "TGT.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "g31X-2WJTavn",
      "metadata": {
        "id": "g31X-2WJTavn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9760cf26-818a-4284-efcf-c4bff602a799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in source (de) vocabulary: 2724\n",
            "Unique tokens in target (en) vocabulary: 2620\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TGT.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "774248b1",
      "metadata": {
        "id": "774248b1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b518a8a3-25cb-440d-aa10-ee963ffff4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "################################################################################################\n",
        "# TODO: play with the batch size. Depending on your machine and dataset you may be able to get #\n",
        "# away with much larger batches.                                                               #\n",
        "################################################################################################\n",
        "BATCH_SIZE = 8 \n",
        "\n",
        "(train_iterator, valid_iterator, test_iterator) = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort_key=lambda x: len(x.src) # batch by length in order to minimize sequence padding\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9b9dc6",
      "metadata": {
        "id": "7e9b9dc6"
      },
      "source": [
        "## Define Model (Encoder, Decoder, Attention Layer, and Decoder with Attention)\n",
        "We define both a \"standard\" decoder and an attention decoder, so that we can evaluate the impact of attention"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d56d9d",
      "metadata": {
        "id": "f1d56d9d"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1684099d",
      "metadata": {
        "id": "1684099d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):        \n",
        "        embedded = self.dropout(self.embedding(src))     \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6880040c",
      "metadata": {
        "id": "6880040c"
      },
      "source": [
        "### Vanilla Decoder (no attention mechanism)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4f96ce68",
      "metadata": {
        "id": "4f96ce68",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = vocab_size\n",
        "        self.hid_dim = dec_hid_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear(dec_hid_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        #\n",
        "        # On the first time step, the hidden tensor \n",
        "        # (the context vector from the encoder) is only 2d, \n",
        "        # so we unsqueeze it.\n",
        "        #\n",
        "        if len(hidden.shape) == 2:\n",
        "            hidden = hidden.unsqueeze(0)\n",
        "            \n",
        "        input = input.unsqueeze(0)        \n",
        "        embedded = self.dropout(self.embedding(input))                \n",
        "        outputs, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc_out(outputs.squeeze(0)) \n",
        "        # last value returned is for attention. Since vanilla model doesn't have attention, this value is None.       \n",
        "        return prediction, hidden, None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19896e5d",
      "metadata": {
        "id": "19896e5d"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "16c21381",
      "metadata": {
        "id": "16c21381",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #\n",
        "        # Repeat decoder hidden state src_len times in order to concatenate it \n",
        "        # with the encoder outputs.\n",
        "        #\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        # energy shape: [batch size, src len, dec hid dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
        "        # attention shape: [batch size, src len]\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        return F.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23ce296",
      "metadata": {
        "id": "f23ce296"
      },
      "source": [
        "### Decoder with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f864c368",
      "metadata": {
        "id": "f864c368",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs) \n",
        "        a = a.unsqueeze(1)\n",
        "                \n",
        "        #\n",
        "        # Get weighted sum of encoder states (weighted by attention vector)\n",
        "        #\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "                \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #\n",
        "        # Also feed the input embedding and the attended encoder representation \n",
        "        # to the fully connected output layer.\n",
        "        #\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "                \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5d524e",
      "metadata": {
        "id": "9c5d524e"
      },
      "source": [
        "## Putting it all together (the Seq2Seq model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0ce38f36",
      "metadata": {
        "id": "0ce38f36",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            ################################################################## #\n",
        "            # TODO*: change to accomodate the AttentionDecoder forward() call.  #\n",
        "            #       You will also need to change a line in the next cell (look # \n",
        "            #       for asterisk)\n",
        "            ##################################################################\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)  \n",
        "\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "\n",
        "            #################################################################\n",
        "            # TODO: (Bonus task) implement teacher forcing here             #\n",
        "            #################################################################\n",
        "            input = trg[t]\n",
        "\n",
        "\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee34bc2",
      "metadata": {
        "id": "1ee34bc2"
      },
      "source": [
        "## Training Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a3f99fc0",
      "metadata": {
        "id": "a3f99fc0",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eba22c0-8e54-4223-85cc-0dd8f344934b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(2724, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): AttentionDecoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(2620, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=2620, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TGT.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "###################################################################################################\n",
        "# TODO*:                                                                                           #\n",
        "# The following line defines the decoder as a Vanilla RNN (GRU) Decoder (i.e. no attention).      #\n",
        "# Your task is to update this line to use the Bahdanau decoder (AttentionDecoder). You will       #\n",
        "# need to check out the __init__ method of AttentionDecoder to make sure you are passing it the   #\n",
        "# appropriate args.                                                                               #\n",
        "###################################################################################################\n",
        "\n",
        "# dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, DEC_DROPOUT)\n",
        "dec = AttentionDecoder(OUTPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "# output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention\n",
        "\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b365ae00",
      "metadata": {
        "id": "b365ae00",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    print(\"Starting training...\")\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.tgt\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, 0.5)  # use teacher forcing during training only.\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)        \n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4e53ea4e",
      "metadata": {
        "id": "4e53ea4e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.tgt\n",
        "            output = model(src, trg, 0) # turn off teacher forcing   \n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "83178a05",
      "metadata": {
        "id": "83178a05",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "71bac6e4",
      "metadata": {
        "id": "71bac6e4",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7084ebda-6f8a-43f1-8098-90507d15f4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 9s\n",
            "\tTrain Loss: 5.957\n",
            "\t Val. Loss: 5.452\n",
            "Starting training...\n",
            "Epoch: 02 | Time: 0m 8s\n",
            "\tTrain Loss: 4.937\n",
            "\t Val. Loss: 5.115\n",
            "Starting training...\n",
            "Epoch: 03 | Time: 0m 8s\n",
            "\tTrain Loss: 4.258\n",
            "\t Val. Loss: 4.890\n",
            "Starting training...\n",
            "Epoch: 04 | Time: 0m 8s\n",
            "\tTrain Loss: 3.560\n",
            "\t Val. Loss: 4.902\n",
            "Starting training...\n",
            "Epoch: 05 | Time: 0m 8s\n",
            "\tTrain Loss: 2.820\n",
            "\t Val. Loss: 4.955\n",
            "Starting training...\n",
            "Epoch: 06 | Time: 0m 8s\n",
            "\tTrain Loss: 2.081\n",
            "\t Val. Loss: 5.107\n",
            "Starting training...\n",
            "Epoch: 07 | Time: 0m 8s\n",
            "\tTrain Loss: 1.467\n",
            "\t Val. Loss: 5.284\n",
            "Starting training...\n",
            "Epoch: 08 | Time: 0m 8s\n",
            "\tTrain Loss: 1.001\n",
            "\t Val. Loss: 5.454\n",
            "Starting training...\n",
            "Epoch: 09 | Time: 0m 8s\n",
            "\tTrain Loss: 0.682\n",
            "\t Val. Loss: 5.632\n",
            "Starting training...\n",
            "Epoch: 10 | Time: 0m 8s\n",
            "\tTrain Loss: 0.487\n",
            "\t Val. Loss: 5.750\n",
            "Starting training...\n",
            "Epoch: 11 | Time: 0m 8s\n",
            "\tTrain Loss: 0.375\n",
            "\t Val. Loss: 5.909\n",
            "Starting training...\n",
            "Epoch: 12 | Time: 0m 8s\n",
            "\tTrain Loss: 0.291\n",
            "\t Val. Loss: 6.043\n",
            "Starting training...\n",
            "Epoch: 13 | Time: 0m 8s\n",
            "\tTrain Loss: 0.243\n",
            "\t Val. Loss: 6.179\n",
            "Starting training...\n",
            "Epoch: 14 | Time: 0m 8s\n",
            "\tTrain Loss: 0.201\n",
            "\t Val. Loss: 6.247\n",
            "Starting training...\n",
            "Epoch: 15 | Time: 0m 10s\n",
            "\tTrain Loss: 0.172\n",
            "\t Val. Loss: 6.364\n",
            "Starting training...\n",
            "Epoch: 16 | Time: 0m 8s\n",
            "\tTrain Loss: 0.175\n",
            "\t Val. Loss: 6.377\n",
            "Starting training...\n",
            "Epoch: 17 | Time: 0m 8s\n",
            "\tTrain Loss: 0.142\n",
            "\t Val. Loss: 6.430\n",
            "Starting training...\n",
            "Epoch: 18 | Time: 0m 8s\n",
            "\tTrain Loss: 0.139\n",
            "\t Val. Loss: 6.447\n",
            "Starting training...\n",
            "Epoch: 19 | Time: 0m 8s\n",
            "\tTrain Loss: 0.132\n",
            "\t Val. Loss: 6.479\n",
            "Starting training...\n",
            "Epoch: 20 | Time: 0m 8s\n",
            "\tTrain Loss: 0.117\n",
            "\t Val. Loss: 6.604\n",
            "Starting training...\n",
            "Epoch: 21 | Time: 0m 8s\n",
            "\tTrain Loss: 0.124\n",
            "\t Val. Loss: 6.691\n",
            "Starting training...\n",
            "Epoch: 22 | Time: 0m 8s\n",
            "\tTrain Loss: 0.129\n",
            "\t Val. Loss: 6.678\n",
            "Starting training...\n",
            "Epoch: 23 | Time: 0m 8s\n",
            "\tTrain Loss: 0.122\n",
            "\t Val. Loss: 6.689\n",
            "Starting training...\n",
            "Epoch: 24 | Time: 0m 8s\n",
            "\tTrain Loss: 0.124\n",
            "\t Val. Loss: 6.764\n",
            "Starting training...\n",
            "Epoch: 25 | Time: 0m 8s\n",
            "\tTrain Loss: 0.120\n",
            "\t Val. Loss: 6.843\n",
            "Starting training...\n",
            "Epoch: 26 | Time: 0m 8s\n",
            "\tTrain Loss: 0.114\n",
            "\t Val. Loss: 6.946\n",
            "Starting training...\n",
            "Epoch: 27 | Time: 0m 8s\n",
            "\tTrain Loss: 0.123\n",
            "\t Val. Loss: 6.943\n",
            "Starting training...\n",
            "Epoch: 28 | Time: 0m 8s\n",
            "\tTrain Loss: 0.117\n",
            "\t Val. Loss: 7.026\n",
            "Starting training...\n",
            "Epoch: 29 | Time: 0m 8s\n",
            "\tTrain Loss: 0.111\n",
            "\t Val. Loss: 6.978\n",
            "Starting training...\n",
            "Epoch: 30 | Time: 0m 8s\n",
            "\tTrain Loss: 0.109\n",
            "\t Val. Loss: 7.085\n",
            "Starting training...\n",
            "Epoch: 31 | Time: 0m 8s\n",
            "\tTrain Loss: 0.109\n",
            "\t Val. Loss: 7.057\n",
            "Starting training...\n",
            "Epoch: 32 | Time: 0m 8s\n",
            "\tTrain Loss: 0.110\n",
            "\t Val. Loss: 7.118\n",
            "Starting training...\n",
            "Epoch: 33 | Time: 0m 8s\n",
            "\tTrain Loss: 0.118\n",
            "\t Val. Loss: 7.222\n",
            "Starting training...\n",
            "Epoch: 34 | Time: 0m 8s\n",
            "\tTrain Loss: 0.117\n",
            "\t Val. Loss: 7.144\n",
            "Starting training...\n",
            "Epoch: 35 | Time: 0m 8s\n",
            "\tTrain Loss: 0.110\n",
            "\t Val. Loss: 7.283\n",
            "Starting training...\n",
            "Epoch: 36 | Time: 0m 8s\n",
            "\tTrain Loss: 0.110\n",
            "\t Val. Loss: 7.357\n",
            "Starting training...\n",
            "Epoch: 37 | Time: 0m 8s\n",
            "\tTrain Loss: 0.106\n",
            "\t Val. Loss: 7.396\n",
            "Starting training...\n",
            "Epoch: 38 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 7.422\n",
            "Starting training...\n",
            "Epoch: 39 | Time: 0m 8s\n",
            "\tTrain Loss: 0.099\n",
            "\t Val. Loss: 7.528\n",
            "Starting training...\n",
            "Epoch: 40 | Time: 0m 8s\n",
            "\tTrain Loss: 0.106\n",
            "\t Val. Loss: 7.485\n",
            "Starting training...\n",
            "Epoch: 41 | Time: 0m 8s\n",
            "\tTrain Loss: 0.103\n",
            "\t Val. Loss: 7.529\n",
            "Starting training...\n",
            "Epoch: 42 | Time: 0m 8s\n",
            "\tTrain Loss: 0.106\n",
            "\t Val. Loss: 7.461\n",
            "Starting training...\n",
            "Epoch: 43 | Time: 0m 8s\n",
            "\tTrain Loss: 0.104\n",
            "\t Val. Loss: 7.532\n",
            "Starting training...\n",
            "Epoch: 44 | Time: 0m 8s\n",
            "\tTrain Loss: 0.103\n",
            "\t Val. Loss: 7.652\n",
            "Starting training...\n",
            "Epoch: 45 | Time: 0m 8s\n",
            "\tTrain Loss: 0.108\n",
            "\t Val. Loss: 7.591\n",
            "Starting training...\n",
            "Epoch: 46 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 7.646\n",
            "Starting training...\n",
            "Epoch: 47 | Time: 0m 8s\n",
            "\tTrain Loss: 0.100\n",
            "\t Val. Loss: 7.694\n",
            "Starting training...\n",
            "Epoch: 48 | Time: 0m 8s\n",
            "\tTrain Loss: 0.099\n",
            "\t Val. Loss: 7.622\n",
            "Starting training...\n",
            "Epoch: 49 | Time: 0m 8s\n",
            "\tTrain Loss: 0.100\n",
            "\t Val. Loss: 7.664\n",
            "Starting training...\n",
            "Epoch: 50 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 7.806\n",
            "Starting training...\n",
            "Epoch: 51 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 7.757\n",
            "Starting training...\n",
            "Epoch: 52 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 7.898\n",
            "Starting training...\n",
            "Epoch: 53 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 7.806\n",
            "Starting training...\n",
            "Epoch: 54 | Time: 0m 8s\n",
            "\tTrain Loss: 0.098\n",
            "\t Val. Loss: 7.943\n",
            "Starting training...\n",
            "Epoch: 55 | Time: 0m 8s\n",
            "\tTrain Loss: 0.094\n",
            "\t Val. Loss: 7.940\n",
            "Starting training...\n",
            "Epoch: 56 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 7.998\n",
            "Starting training...\n",
            "Epoch: 57 | Time: 0m 8s\n",
            "\tTrain Loss: 0.100\n",
            "\t Val. Loss: 7.990\n",
            "Starting training...\n",
            "Epoch: 58 | Time: 0m 8s\n",
            "\tTrain Loss: 0.103\n",
            "\t Val. Loss: 8.010\n",
            "Starting training...\n",
            "Epoch: 59 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 8.038\n",
            "Starting training...\n",
            "Epoch: 60 | Time: 0m 8s\n",
            "\tTrain Loss: 0.094\n",
            "\t Val. Loss: 8.042\n",
            "Starting training...\n",
            "Epoch: 61 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 8.064\n",
            "Starting training...\n",
            "Epoch: 62 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 8.138\n",
            "Starting training...\n",
            "Epoch: 63 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.162\n",
            "Starting training...\n",
            "Epoch: 64 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 8.188\n",
            "Starting training...\n",
            "Epoch: 65 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.220\n",
            "Starting training...\n",
            "Epoch: 66 | Time: 0m 8s\n",
            "\tTrain Loss: 0.102\n",
            "\t Val. Loss: 8.243\n",
            "Starting training...\n",
            "Epoch: 67 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 8.240\n",
            "Starting training...\n",
            "Epoch: 68 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 8.372\n",
            "Starting training...\n",
            "Epoch: 69 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 8.436\n",
            "Starting training...\n",
            "Epoch: 70 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 8.336\n",
            "Starting training...\n",
            "Epoch: 71 | Time: 0m 8s\n",
            "\tTrain Loss: 0.096\n",
            "\t Val. Loss: 8.375\n",
            "Starting training...\n",
            "Epoch: 72 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 8.390\n",
            "Starting training...\n",
            "Epoch: 73 | Time: 0m 9s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 8.464\n",
            "Starting training...\n",
            "Epoch: 74 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 8.367\n",
            "Starting training...\n",
            "Epoch: 75 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.501\n",
            "Starting training...\n",
            "Epoch: 76 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 8.484\n",
            "Starting training...\n",
            "Epoch: 77 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 8.443\n",
            "Starting training...\n",
            "Epoch: 78 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.443\n",
            "Starting training...\n",
            "Epoch: 79 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 8.487\n",
            "Starting training...\n",
            "Epoch: 80 | Time: 0m 8s\n",
            "\tTrain Loss: 0.099\n",
            "\t Val. Loss: 8.469\n",
            "Starting training...\n",
            "Epoch: 81 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.644\n",
            "Starting training...\n",
            "Epoch: 82 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 8.641\n",
            "Starting training...\n",
            "Epoch: 83 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 8.682\n",
            "Starting training...\n",
            "Epoch: 84 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 8.657\n",
            "Starting training...\n",
            "Epoch: 85 | Time: 0m 9s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.735\n",
            "Starting training...\n",
            "Epoch: 86 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 8.772\n",
            "Starting training...\n",
            "Epoch: 87 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.858\n",
            "Starting training...\n",
            "Epoch: 88 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.728\n",
            "Starting training...\n",
            "Epoch: 89 | Time: 0m 10s\n",
            "\tTrain Loss: 0.094\n",
            "\t Val. Loss: 8.833\n",
            "Starting training...\n",
            "Epoch: 90 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 8.836\n",
            "Starting training...\n",
            "Epoch: 91 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.832\n",
            "Starting training...\n",
            "Epoch: 92 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 8.858\n",
            "Starting training...\n",
            "Epoch: 93 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.965\n",
            "Starting training...\n",
            "Epoch: 94 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 8.843\n",
            "Starting training...\n",
            "Epoch: 95 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 9.023\n",
            "Starting training...\n",
            "Epoch: 96 | Time: 0m 8s\n",
            "\tTrain Loss: 0.094\n",
            "\t Val. Loss: 8.982\n",
            "Starting training...\n",
            "Epoch: 97 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 8.948\n",
            "Starting training...\n",
            "Epoch: 98 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.965\n",
            "Starting training...\n",
            "Epoch: 99 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 9.010\n",
            "Starting training...\n",
            "Epoch: 100 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 8.960\n",
            "Starting training...\n",
            "Epoch: 101 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.014\n",
            "Starting training...\n",
            "Epoch: 102 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 8.936\n",
            "Starting training...\n",
            "Epoch: 103 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 9.022\n",
            "Starting training...\n",
            "Epoch: 104 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.087\n",
            "Starting training...\n",
            "Epoch: 105 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 9.042\n",
            "Starting training...\n",
            "Epoch: 106 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 9.052\n",
            "Starting training...\n",
            "Epoch: 107 | Time: 0m 8s\n",
            "\tTrain Loss: 0.084\n",
            "\t Val. Loss: 9.117\n",
            "Starting training...\n",
            "Epoch: 108 | Time: 0m 9s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.106\n",
            "Starting training...\n",
            "Epoch: 109 | Time: 0m 9s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 9.189\n",
            "Starting training...\n",
            "Epoch: 110 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 9.228\n",
            "Starting training...\n",
            "Epoch: 111 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.223\n",
            "Starting training...\n",
            "Epoch: 112 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 9.385\n",
            "Starting training...\n",
            "Epoch: 113 | Time: 0m 8s\n",
            "\tTrain Loss: 0.087\n",
            "\t Val. Loss: 9.400\n",
            "Starting training...\n",
            "Epoch: 114 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 9.374\n",
            "Starting training...\n",
            "Epoch: 115 | Time: 0m 8s\n",
            "\tTrain Loss: 0.098\n",
            "\t Val. Loss: 9.360\n",
            "Starting training...\n",
            "Epoch: 116 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 9.409\n",
            "Starting training...\n",
            "Epoch: 117 | Time: 0m 14s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 9.405\n",
            "Starting training...\n",
            "Epoch: 118 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 9.501\n",
            "Starting training...\n",
            "Epoch: 119 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 9.527\n",
            "Starting training...\n",
            "Epoch: 120 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.510\n",
            "Starting training...\n",
            "Epoch: 121 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.576\n",
            "Starting training...\n",
            "Epoch: 122 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 9.628\n",
            "Starting training...\n",
            "Epoch: 123 | Time: 0m 8s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 9.579\n",
            "Starting training...\n",
            "Epoch: 124 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 9.647\n",
            "Starting training...\n",
            "Epoch: 125 | Time: 0m 9s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.568\n",
            "Starting training...\n",
            "Epoch: 126 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 9.513\n",
            "Starting training...\n",
            "Epoch: 127 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.662\n",
            "Starting training...\n",
            "Epoch: 128 | Time: 0m 9s\n",
            "\tTrain Loss: 0.095\n",
            "\t Val. Loss: 9.668\n",
            "Starting training...\n",
            "Epoch: 129 | Time: 0m 8s\n",
            "\tTrain Loss: 0.096\n",
            "\t Val. Loss: 9.686\n",
            "Starting training...\n",
            "Epoch: 130 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 9.639\n",
            "Starting training...\n",
            "Epoch: 131 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 9.700\n",
            "Starting training...\n",
            "Epoch: 132 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.674\n",
            "Starting training...\n",
            "Epoch: 133 | Time: 0m 8s\n",
            "\tTrain Loss: 0.100\n",
            "\t Val. Loss: 9.634\n",
            "Starting training...\n",
            "Epoch: 134 | Time: 0m 8s\n",
            "\tTrain Loss: 0.088\n",
            "\t Val. Loss: 9.706\n",
            "Starting training...\n",
            "Epoch: 135 | Time: 0m 8s\n",
            "\tTrain Loss: 0.102\n",
            "\t Val. Loss: 9.724\n",
            "Starting training...\n",
            "Epoch: 136 | Time: 0m 8s\n",
            "\tTrain Loss: 0.094\n",
            "\t Val. Loss: 9.765\n",
            "Starting training...\n",
            "Epoch: 137 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 9.788\n",
            "Starting training...\n",
            "Epoch: 138 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 9.805\n",
            "Starting training...\n",
            "Epoch: 139 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.819\n",
            "Starting training...\n",
            "Epoch: 140 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 9.737\n",
            "Starting training...\n",
            "Epoch: 141 | Time: 0m 8s\n",
            "\tTrain Loss: 0.090\n",
            "\t Val. Loss: 9.793\n",
            "Starting training...\n",
            "Epoch: 142 | Time: 0m 8s\n",
            "\tTrain Loss: 0.089\n",
            "\t Val. Loss: 9.841\n",
            "Starting training...\n",
            "Epoch: 143 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 9.856\n",
            "Starting training...\n",
            "Epoch: 144 | Time: 0m 8s\n",
            "\tTrain Loss: 0.097\n",
            "\t Val. Loss: 9.878\n",
            "Starting training...\n",
            "Epoch: 145 | Time: 0m 8s\n",
            "\tTrain Loss: 0.092\n",
            "\t Val. Loss: 9.902\n",
            "Starting training...\n",
            "Epoch: 146 | Time: 0m 8s\n",
            "\tTrain Loss: 0.093\n",
            "\t Val. Loss: 9.922\n",
            "Starting training...\n",
            "Epoch: 147 | Time: 0m 8s\n",
            "\tTrain Loss: 0.086\n",
            "\t Val. Loss: 10.011\n",
            "Starting training...\n",
            "Epoch: 148 | Time: 0m 8s\n",
            "\tTrain Loss: 0.091\n",
            "\t Val. Loss: 10.055\n",
            "Starting training...\n",
            "Epoch: 149 | Time: 0m 8s\n",
            "\tTrain Loss: 0.100\n",
            "\t Val. Loss: 10.050\n",
            "Starting training...\n",
            "Epoch: 150 | Time: 0m 8s\n",
            "\tTrain Loss: 0.098\n",
            "\t Val. Loss: 10.114\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 150\n",
        "CLIP = 1\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "TRG_PAD_IDX = TGT.vocab.stoi[TGT.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i18FFIWhVd63",
      "metadata": {
        "id": "i18FFIWhVd63"
      },
      "source": [
        "## Inference\n",
        "\n",
        "The following blocks are only valid for attention model. If you are executing Vanilla Decoder, then stop here!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PRpSSrIZV5mN",
      "metadata": {
        "id": "PRpSSrIZV5mN"
      },
      "source": [
        "We are now going to machine translate some sentences using our trained attention model.\n",
        "\n",
        "The function takes in sentence to translate, SRC, TGT fields and the model and returns predicted sentence and attention values over the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7nUL2YW9V6SR",
      "metadata": {
        "id": "7nUL2YW9V6SR"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "    # Add start of sentence and end of sentence to the tokens\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    # Numericalize the source sentence\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    # src_indexes shape = [src_len]\n",
        "\n",
        "    # Convert to tensor and add batch dimension.\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # Feed source sentence into encoder\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "    \n",
        "    # create a list to hold the output sentence, initialized with an <sos> token\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    # create a tensor to hold the attention values\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
        "        attentions[i] = attention\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GRzoKw1ZX0_O",
      "metadata": {
        "id": "GRzoKw1ZX0_O"
      },
      "source": [
        "Function to display attention visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "m3gNyABdX1eK",
      "metadata": {
        "id": "m3gNyABdX1eK"
      },
      "outputs": [],
      "source": [
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels(['']+translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jKyChZE9X9uV",
      "metadata": {
        "id": "jKyChZE9X9uV"
      },
      "source": [
        "### Inference on some test sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "UIRzF9X1YBDm",
      "metadata": {
        "id": "UIRzF9X1YBDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276ca58c-4b9f-4cd5-b13a-77972a464484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['i', \"can't\", 'buy', 'a', 'book', 'this', 'expensive.']\n",
            "trg = ['मैं', 'इतनी', 'महंगी', 'किताब', 'नहीं', 'ख़रीद', 'सकता।']\n"
          ]
        }
      ],
      "source": [
        "example_idx = 1\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['tgt']\n",
        "# src = ['how', 'are', 'you']\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "j88NiyfwYO_I",
      "metadata": {
        "id": "j88NiyfwYO_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e852c9f5-535f-475d-cf56-5eacca8a52a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg = ['मैं', 'इतनी', 'महंगी', 'किताब', 'नहीं', 'ख़रीद', 'सकता।', '<eow>']\n"
          ]
        }
      ],
      "source": [
        "translation, attention = translate_sentence(src, SRC, TGT, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "sdnJMH-DYScv",
      "metadata": {
        "id": "sdnJMH-DYScv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ca66fb4-6d15-4417-cd9c-7276d8da67ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2350 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2306 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2311 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2344 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2327 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2326 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2364 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2342 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2350 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2306 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2311 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2344 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2327 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2326 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2364 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2342 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "display_attention(src, translation, attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QSw6F_EhYWQl",
      "metadata": {
        "id": "QSw6F_EhYWQl"
      },
      "source": [
        "### Bleu score calculation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "NkpXBUw2YZkk",
      "metadata": {
        "id": "NkpXBUw2YZkk"
      },
      "outputs": [],
      "source": [
        "# from torchtext.data.metrics import bleu_score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import math\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    bleu_score = []\n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        tgt = vars(datum)['tgt']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append(tgt)\n",
        "        # print(tgt, pred_trg)\n",
        "        bleu_score.append(sentence_bleu([pred_trg], tgt))\n",
        "    print(bleu_score, len(bleu_score))\n",
        "    return sum(bleu_score)/len(bleu_score)\n",
        "        ################################################################\n",
        "        # TODO: call the bleu score function here and return the result#\n",
        "        ################################################################\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "W42BqwGRYdTw",
      "metadata": {
        "id": "W42BqwGRYdTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e731dc16-10a5-49cb-a8cd-884005dde109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.9764165035645784e-232, 1.3127657569660467e-231, 4.603578218506236e-155, 8.636168555094496e-78, 1.646211035903463e-231, 8.166726842395623e-232, 4.4567910894251624e-155, 6.510101141652543e-232, 1.2882297539194154e-231, 5.330020010319017e-232, 1.1200407237786664e-231, 8.166726842395623e-232, 9.073649206312902e-155, 6.686350417856737e-232, 8.166726842395623e-232, 6.061838450024688e-155, 1.0518351895246305e-231, 0, 1.0, 1.0832677820940877e-231, 7.57965434483665e-155, 1.0832677820940877e-231, 0, 0, 5.400301927028362e-232, 0, 9.291879812217675e-232, 5.722633035689358e-155, 1.0003688322288243e-231, 8.962731118674859e-232, 6.684949609530091e-155, 0.6104735835807844, 0, 9.97486269044271e-232, 1.2183324802375697e-231, 1.2183324802375697e-231, 1.1640469867513693e-231, 7.711523862191631e-155, 0, 0, 0, 6.397495320955232e-155, 1.384292958842266e-231, 3.965294799986402e-78, 1.1368587676511996e-231, 0, 9.709385502639237e-232, 1.5319719891192393e-231, 6.484592771860512e-155, 6.085166479973199e-232, 1.0, 1.4488496539373276e-231, 0, 9.788429383461836e-232, 6.397495320955232e-155, 0.537284965911771, 1.4488496539373276e-231, 7.711523862191631e-155, 1.2882297539194154e-231, 0, 8.676910262183261e-232, 7.183445846156676e-155, 1.4488496539373276e-231, 9.788429383461836e-232, 1.384292958842266e-231, 1.1896457329133973e-231, 1.2882297539194154e-231, 0.4111336169005197, 8.396161215621529e-232, 4.446808895758207e-78, 5.157006819435075e-155, 0.4347208719449914, 1.0244914152188952e-231, 1.384292958842266e-231, 0, 1.1931009847695213e-231, 0, 0.4671379777282001, 3.418291552750845e-232, 8.875814970513353e-232, 0, 1.1200407237786664e-231, 1.3483065280626046e-231, 0, 1.1640469867513693e-231, 0, 6.570351225189682e-232, 1.0032743411283238e-231, 0, 0, 8.324264127738903e-232, 1.0032743411283238e-231, 9.788429383461836e-232, 9.291879812217675e-232, 1.0022971981925033e-231, 0, 1.1640469867513693e-231, 1.0547686614863434e-154, 0, 1.1931009847695213e-231, 1.0032743411283238e-231, 0, 9.709385502639237e-232, 5.635809992474887e-232, 5.094696780347207e-155, 1.258141043412406e-231, 7.711523862191631e-155, 0, 1.0832677820940877e-231, 7.951455490316087e-232, 1.2967862918337585e-231, 1.133422688662942e-154, 0, 1.2183324802375697e-231, 0, 0, 0, 0, 0, 0, 8.422437779564611e-232, 1.0518351895246305e-231, 7.57965434483665e-155, 0, 1.384292958842266e-231, 9.853445011990208e-232, 0, 8.436497969708995e-232, 6.439988060393651e-155, 0.5, 1.2882297539194154e-231, 0, 4.797597231912944e-78, 9.257324954728539e-232, 0, 0, 1.2183324802375697e-231, 0, 1.0244914152188952e-231, 4.721756180471194e-155, 6.056071959384271e-232, 7.57965434483665e-155, 0, 0, 1.2882297539194154e-231, 1.1931009847695213e-231, 1.1200407237786664e-231, 1.1640469867513693e-231, 7.57965434483665e-155, 9.594503055152632e-232, 1.6034157163765524e-231, 1.0977058971259433e-231, 0, 1.0518351895246305e-231, 0, 0, 1.2213386697554703e-77, 6.968148412761692e-155, 1.1368587676511996e-231, 1.0518351895246305e-231, 5.330020010319017e-232, 1.0832677820940877e-231, 8.34076112986429e-232, 1.2778269941762074e-231, 7.445183326929416e-232, 0, 0, 0, 0, 5.396466934950335e-155, 1.2882297539194154e-231, 1.646211035903463e-231, 1.1896457329133973e-231, 1.3127657569660467e-231, 1.2882297539194154e-231, 7.711523862191631e-155, 1.1200407237786664e-231, 1.2508498911928379e-231, 1.1640469867513693e-231, 6.206021746903507e-78, 5.775353993361614e-78, 0, 1.0032743411283238e-231, 0, 0, 0, 2.043449459421412e-78, 3.935039685526131e-155, 7.107197028258987e-232, 1.384292958842266e-231, 8.38826642100846e-155, 8.416851712392762e-232, 9.418382295637229e-232, 7.711523862191631e-155, 2.360328799140421e-155, 0.6104735835807844, 1.331960397810445e-231, 1.0, 3.630015775438828e-78, 1.1200407237786664e-231, 9.283142785759642e-155, 0, 5.472278756504876e-232, 1.2183324802375697e-231, 0.5578002860768766, 0.668740304976422, 1.2213386697554703e-77, 1.2508498911928379e-231, 1.171778691554733e-231, 0.5946035575013605, 1.3165594234639305e-231, 1.0009379942300742e-231, 6.484592771860512e-155, 1.0719249972567852e-154, 1.0032743411283238e-231, 1.2882297539194154e-231, 1.1409851298103347e-231, 1.0244914152188952e-231, 1.0, 0, 0, 0, 0.668740304976422, 5.236405306969006e-155, 0, 1.154647032204335e-231, 0, 0, 1.331960397810445e-231, 0, 1.1409851298103347e-231, 8.214546595247418e-155, 0.5946035575013605, 9.97486269044271e-232, 1.2183324802375697e-231, 0, 1.384292958842266e-231, 0, 1.2183324802375697e-231, 7.380245217279165e-78, 6.86809206056511e-78, 0.2948682411907622, 1.0832677820940877e-231, 1.2183324802375697e-231, 9.418382295637229e-232, 1.1200407237786664e-231, 9.788429383461836e-232, 0, 0.537284965911771, 1.1200407237786664e-231, 5.474320712955125e-232, 1.0032743411283238e-231, 1.0518351895246305e-231, 4.4646672960328985e-78, 9.109159947227211e-232, 0, 5.092529201164552e-232, 7.445183326929416e-232, 6.147254555356275e-78, 0, 5.395774370246974e-78, 1.2882297539194154e-231, 0, 0.8091067115702212, 0, 1.0003688322288243e-231, 6.085166479973199e-232, 0.6104735835807844, 1.171778691554733e-231, 0.5410822690539396, 1.0547686614863434e-154, 8.636168555094496e-78, 7.711523862191631e-155, 9.283142785759642e-155, 1.0832677820940877e-231, 1.7485856847061088e-232, 0, 7.57965434483665e-155, 1.04198122363916e-154, 4.677477553605556e-78, 3.690840039559348e-232, 2.0138900446751835e-232, 6.552765724042392e-155, 0, 7.711523862191631e-155, 8.396161215621529e-232, 1.2183324802375697e-231, 1.2183324802375697e-231, 4.481994719908145e-232, 0, 7.711523862191631e-155, 2.1266336439355304e-155, 1.2183324802375697e-231, 1.0244914152188952e-231, 0, 9.788429383461836e-232, 5.722633035689358e-155, 1.1200407237786664e-231, 0, 4.677477553605556e-78, 5.722633035689358e-155, 1.0832677820940877e-231, 0.32260135189272865, 0, 9.97486269044271e-232, 5.395774370246974e-78, 7.296382734947757e-232, 1.154647032204335e-231, 7.060301868108111e-232, 0.42383656282787796, 6.570351225189682e-232, 1.0003688322288243e-231, 0, 1.1640469867513693e-231, 1.0518351895246305e-231, 1.384292958842266e-231, 1.1200407237786664e-231, 0, 0, 0, 0.7598356856515925, 0, 0, 0, 1.2183324802375697e-231, 9.709385502639237e-232, 4.640083527732319e-78, 1.384292958842266e-231, 1.331960397810445e-231, 6.510101141652543e-232, 0, 0, 1.2183324802375697e-231, 0, 3.9876353728947065e-78, 0, 6.147254555356275e-78, 9.283142785759642e-155, 7.107197028258987e-232, 1.04198122363916e-154, 7.521821744402224e-232, 7.060301868108111e-232, 0, 0, 0, 1.331960397810445e-231, 4.739132419722992e-232, 0, 1.331960397810445e-231, 1.0518351895246305e-231, 6.657922819542466e-232, 8.166726842395623e-232, 1.0518351895246305e-231, 9.291879812217675e-232, 1.0003688322288243e-231, 1.2508498911928379e-231, 0, 7.380245217279165e-78, 0, 3.841240254629353e-155, 0, 1.0032743411283238e-231, 1.1200407237786664e-231, 0, 5.233427736988301e-155, 7.176381577237209e-155, 8.636168555094496e-78, 0, 1.2508498911928379e-231, 0.6434588841607617, 6.686350417856737e-232, 1.4488496539373276e-231, 0, 8.436497969708995e-232, 6.968148412761692e-155, 9.711929667259895e-232, 8.166726842395623e-232, 0, 0, 0, 1.0832677820940877e-231, 1.4488496539373276e-231, 0, 0, 7.100514228897259e-155, 7.813508425061864e-232, 0, 4.597292750167502e-155, 1.2183324802375697e-231, 7.380245217279165e-78, 0, 1.2387197655613557e-231, 3.7690910616910046e-155, 0, 1.1008876702055895e-231, 4.248822083050608e-232, 7.711523862191631e-155, 1.1640469867513693e-231, 7.060301868108111e-232, 0, 7.236523273960503e-232, 1.0832677820940877e-231, 4.1382219658909647e-78, 1.2508498911928379e-231, 0, 0, 5.467133248249545e-155, 1.384292958842266e-231, 1.0547686614863434e-154, 1.2183324802375697e-231, 1.0244914152188952e-231, 5.395774370246974e-78, 7.57965434483665e-155, 9.291879812217675e-232, 5.094696780347207e-155, 4.034282314146679e-78, 6.237049021538533e-232, 0, 1.2882297539194154e-231, 1.1200407237786664e-231, 0, 6.484592771860512e-155, 4.888731610154635e-78, 0, 1.1200407237786664e-231, 0.3655552228545123, 9.53091075863908e-155, 8.416851712392762e-232, 1.0032743411283238e-231, 0, 0, 7.227401369829121e-78, 1.4488496539373276e-231, 1.5319719891192393e-231, 6.805395922591311e-155, 1.0] 436\n",
            "BLEU score = 0.04\n"
          ]
        }
      ],
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TGT, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.translate.bleu_score import sentence_bleu\n",
        "# reference = [\n",
        "#     'this is a dog'.split(),\n",
        "#     'it is dog'.split(),\n",
        "#     'dog it is'.split(),\n",
        "#     'a dog, it is'.split() \n",
        "# ]\n",
        "# candidate = 'it is dog'.split()\n",
        "\n",
        "# print(reference, candidate)\n",
        "# print('BLEU score -> {}'.format(sentence_bleu(reference, candidate )))\n",
        "\n",
        "# candidate = 'it is a dog'.split()\n",
        "# print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
      ],
      "metadata": {
        "id": "tWsOliY_RqrC"
      },
      "id": "tWsOliY_RqrC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT3 Sequence to Sequence"
      ],
      "metadata": {
        "id": "U-ayjBEDW4AM"
      },
      "id": "U-ayjBEDW4AM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets compare the above Seq_to_Seq model with GPT3 model. You have already seen how to create the Example Class, GPT3 class, read data and how to submit a prompt to the GPT3. \n",
        "\n",
        "So Let's do it."
      ],
      "metadata": {
        "id": "djLGHgq5vCtr"
      },
      "id": "djLGHgq5vCtr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install the openAI library"
      ],
      "metadata": {
        "id": "ChPNpqsTfKbv"
      },
      "id": "ChPNpqsTfKbv"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JktOWGXpa3iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddb1860-d655-4ae0-92f3-11009b9ff767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.24.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.24.0-py3-none-any.whl size=55926 sha256=a756ac7807bcca2efb34f12d4a98556a8732139937d68546821bbf8faa8f1f3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/2b/ee/7649ac33c142e3fde2081bd8769337b5e75710fd4b885cd2c6\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.24.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ],
      "id": "JktOWGXpa3iD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import all necessary libraries"
      ],
      "metadata": {
        "id": "scOXfzS0chB6"
      },
      "id": "scOXfzS0chB6"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "zaDH0LaLa69S"
      },
      "execution_count": 136,
      "outputs": [],
      "id": "zaDH0LaLa69S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Use the shared api key"
      ],
      "metadata": {
        "id": "p1tFpfudehEl"
      },
      "id": "p1tFpfudehEl"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Insert your api key\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "qBi9dvBVedaN"
      },
      "execution_count": 137,
      "outputs": [],
      "id": "qBi9dvBVedaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Create a class Example that will create the different input-output pairs for the GPT3 model"
      ],
      "metadata": {
        "id": "Xge4QCh6cvbi"
      },
      "id": "Xge4QCh6cvbi"
    },
    {
      "cell_type": "code",
      "source": [
        "class Example:\n",
        "\n",
        "   # Stores an input, output pair and formats it to prime the model\n",
        "   def __init__(self, input, output):\n",
        "       self.input = input\n",
        "       self.output = output\n",
        "       self.id = uuid.uuid4().hex\n",
        "\n",
        "   # To obtain the input provided for an example\n",
        "   def get_input(self):\n",
        "       return self.input\n",
        "\n",
        "   # To obtain the output provided for an example\n",
        "   def get_output(self):\n",
        "       return self.output\n",
        "\n",
        "   # To obtain the unique id of an example\n",
        "   def get_id(self):\n",
        "       return self.id"
      ],
      "metadata": {
        "id": "e8wY1V5Ja-Sa"
      },
      "execution_count": 138,
      "outputs": [],
      "id": "e8wY1V5Ja-Sa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Create a GPT-3 class that will manage different parameters of the GPT-3 model and create prompts for the model"
      ],
      "metadata": {
        "id": "upc3yjMqdhx4"
      },
      "id": "upc3yjMqdhx4"
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT3:\n",
        "\n",
        "   # initialises parameters and adds default values\n",
        "   def __init__(self, describe_task = \"\", engine='davinci', temperature=0.5, max_tokens=100,\n",
        "\n",
        "       input_prefix=\"input: \", input_suffix=\"\\n\", output_prefix=\"output: \",\n",
        "       output_suffix=\"\\n\\n\", append_output_prefix_to_query=False):\n",
        "       self.examples = {}\n",
        "       self.engine = engine\n",
        "       self.temperature = temperature\n",
        "       self.max_tokens = max_tokens\n",
        "       self.input_prefix = input_prefix\n",
        "       self.input_suffix = input_suffix\n",
        "       self.output_prefix = output_prefix\n",
        "       self.output_suffix = output_suffix\n",
        "       self.append_output_prefix_to_query = append_output_prefix_to_query\n",
        "       self.stop = (output_suffix + input_prefix).strip()\n",
        "       self.description = describe_task\n",
        "\n",
        "   # Adds an example to the model object. Example is an instance of the Example class.\n",
        "   def add_example(self, ex):\n",
        "       self.examples[ex.get_id()] = ex\n",
        "\n",
        "   # Converts all the examples to a particular format to prime the model.\n",
        "   def get_prime_text(self):\n",
        "       return \"\".join(\n",
        "           [self.format_example(ex) for ex in self.examples.values()])\n",
        "\n",
        "   # Creates a query for the API request\n",
        "   def craft_query(self, prompt):\n",
        "       #print(\"description in cratft query\",self.description)\n",
        "       q = self.description+self.get_prime_text(\n",
        "       ) + self.input_prefix + prompt + self.input_suffix\n",
        "\n",
        "       #print(q)\n",
        "       if self.append_output_prefix_to_query:\n",
        "           q = q + self.output_prefix\n",
        "       return q\n",
        "\n",
        "   # Calls the API using the Completion endpoint with the specified values of the parameters\n",
        "   def submit_request(self, prompt):\n",
        "       response = openai.Completion.create(engine=self.engine,\n",
        "                                           prompt=self.craft_query(prompt),\n",
        "                                           max_tokens=self.max_tokens,\n",
        "                                           temperature=self.temperature,\n",
        "                                           top_p=1,\n",
        "                                           n=1,\n",
        "                                           stream=False,\n",
        "                                           stop=self.stop)\n",
        "       return response\n",
        "\n",
        "   # Formats the input output pair with appropriate prefixes and suffixes\n",
        "   def format_example(self, ex):\n",
        "       return self.input_prefix + ex.get_input(\n",
        "       ) + self.input_suffix + self.output_prefix + ex.get_output(\n",
        "       ) + self.output_suffix"
      ],
      "metadata": {
        "id": "g6BVS6-AbQkE"
      },
      "execution_count": 139,
      "outputs": [],
      "id": "g6BVS6-AbQkE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Read data from the drive."
      ],
      "metadata": {
        "id": "hjmtl4Lhj3nr"
      },
      "id": "hjmtl4Lhj3nr"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e014fad1-e0da-46e1-cfe1-67cd387c902d",
        "id": "3jx3mpT4cMc_"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "id": "3jx3mpT4cMc_"
    },
    {
      "cell_type": "code",
      "source": [
        "ls \"/content/drive/MyDrive/IUB Fall 22/Advance NLP/Practicals/hindi_data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b3f39c-20f5-4a70-b69c-cacb5c9d4402",
        "id": "Rc6Ik5-ocMdI"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.tsv  train.tsv  val.tsv\n"
          ]
        }
      ],
      "id": "Rc6Ik5-ocMdI"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Upload the csv on Google Colab from https://github.com/hardikasnani/LING-L645/blob/main/GPT3%20Practical/Task%202/Title_Abstract.csv\n",
        "# and then read it below\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/IUB Fall 22/Advance NLP/Practicals/hindi_data/\""
      ],
      "metadata": {
        "id": "cT8ahK4Aj08G"
      },
      "execution_count": 143,
      "outputs": [],
      "id": "cT8ahK4Aj08G"
    },
    {
      "cell_type": "code",
      "source": [
        "translation_train_df= pd.read_csv(file_path + 'train.tsv', sep='\\t', header=None)\n",
        "\n",
        "\n",
        "translation_test_df= pd.read_csv(file_path + 'test.tsv', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "CqDbZo4rcV0b"
      },
      "id": "CqDbZo4rcV0b",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Create the object of GPT3 Class and few shots to the GPT3"
      ],
      "metadata": {
        "id": "nSoT8r22vmkW"
      },
      "id": "nSoT8r22vmkW"
    },
    {
      "cell_type": "code",
      "source": [
        "gpt3_tweet = GPT3(engine=\"davinci\", temperature=0.3, max_tokens=60)\n",
        "train_df=translation_train_df.sample(n=20) \n",
        "for i in range(len(train_df)):\n",
        "  example=[train_df.iloc[i][0], train_df.iloc[i][1]]\n",
        "  gpt3_tweet.add_example(Example(example[0],example[1]))"
      ],
      "metadata": {
        "id": "TvUz3WAFj51O"
      },
      "id": "TvUz3WAFj51O",
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Create the fuction predict sequence translation using the test dataset."
      ],
      "metadata": {
        "id": "912dHUPUvskv"
      },
      "id": "912dHUPUvskv"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_seq_to_seq(test_data):\n",
        "  bleu_score = []\n",
        "  for i in range(len(test_data)):\n",
        "    prompt=test_data.iloc[i][0]\n",
        "    output=gpt3_tweet.submit_request(prompt)\n",
        "    predicted_translation = (output.choices[0].text).split(\":\")[1].split(\" \")\n",
        "    actual_translation = test_data.iloc[i][1].split(\" \")\n",
        "    print(i, prompt, [predicted_translation], actual_translation)\n",
        "    bleu_score.append(sentence_bleu([predicted_translation], actual_translation))\n",
        "  print(bleu_score)\n",
        "  return sum(bleu_score)/len(bleu_score)\n"
      ],
      "metadata": {
        "id": "VLQcSJqlbTah"
      },
      "id": "VLQcSJqlbTah",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = predict_seq_to_seq(translation_test_df)\n",
        "print(f'BLEU score = {bleu_score:.2f}')"
      ],
      "metadata": {
        "id": "UkL3emvKewbI"
      },
      "id": "UkL3emvKewbI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbGMDKHEe0GM"
      },
      "id": "XbGMDKHEe0GM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}