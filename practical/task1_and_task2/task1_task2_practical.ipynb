{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rK_1KXQeykvq",
        "Nb-6_evNyb3Z",
        "NKaE_WFw1_jO",
        "CaMLXuk10TlG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Section 1: Install Dependencies**"
      ],
      "metadata": {
        "id": "rK_1KXQeykvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65H8GufV4vn7",
        "outputId": "a278a6b0-46e2-45ee-93c2-2792507a490e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.24.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 26.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.24.0-py3-none-any.whl size=55926 sha256=e762a0f976e5f6306fb5cbc9bd9348ba43545c862b906ae1a96fc430abd23037\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/2b/ee/7649ac33c142e3fde2081bd8769337b5e75710fd4b885cd2c6\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.24.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Section 2: Importing Relevant Modules**"
      ],
      "metadata": {
        "id": "Nb-6_evNyb3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import openai\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "BKiHhGQlDC_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TODO 1:** Go to https://beta.openai.com/playground and there must be a personal icon on the top right hand side, click on that and go to \"View API Keys\". It will open a new view and you can see the \"Secret Key\" there, copy the same and paste it within the quotes below. "
      ],
      "metadata": {
        "id": "dk8Ufz-6ysJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "openai.api_key= \"\" ################ TODO : Enter Your Api Key Here\"#############"
      ],
      "metadata": {
        "id": "3JzDXsJ3473L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Section 3: Important Classes for the Code**"
      ],
      "metadata": {
        "id": "NKaE_WFw1_jO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example Class:** The example class takes input, output, id. We are using this class later to train the gpt3 (few shot learning) with an input and output"
      ],
      "metadata": {
        "id": "29tgwqVKzyFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Example:\n",
        "\n",
        "   # Stores an input, output pair and formats it to prime the model\n",
        "   def __init__(self, input, output):\n",
        "       self.input = input\n",
        "       self.output = output\n",
        "       self.id = uuid.uuid4().hex\n",
        "\n",
        "   # To obtain the input provided for an example\n",
        "   def get_input(self):\n",
        "       return self.input\n",
        "\n",
        "   # To obtain the output provided for an example\n",
        "   def get_output(self):\n",
        "       return self.output\n",
        "\n",
        "   # To obtain the unique id of an example\n",
        "   def get_id(self):\n",
        "       return self.id"
      ],
      "metadata": {
        "id": "1gTheJmk48tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GPT3 Class:** \n",
        "</br>\n",
        "\n",
        "**Important things to note:**\n",
        "*   The gpt3 class will take inputs of **engines, temperature, max_tokens,** description and other important parameters to be sent to gpt3\n",
        "*   The submit_request method will send the request to openai and receive a response in return. \n",
        "</br>\n",
        "\n",
        "*This class is very important for this practical. Its important to understand this well*"
      ],
      "metadata": {
        "id": "CaMLXuk10TlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT3:\n",
        "\n",
        "   # initialises parameters and adds default values\n",
        "   def __init__(self, describe_task = \"\", engine='davinci', temperature=0.5, max_tokens=100,\n",
        "\n",
        "       input_prefix=\"input: \", input_suffix=\"\\n\", output_prefix=\"output: \",\n",
        "       output_suffix=\"\\n\\n\", append_output_prefix_to_query=False):\n",
        "       self.examples = {}\n",
        "       self.engine = engine\n",
        "       self.temperature = temperature\n",
        "       self.max_tokens = max_tokens\n",
        "       self.input_prefix = input_prefix\n",
        "       self.input_suffix = input_suffix\n",
        "       self.output_prefix = output_prefix\n",
        "       self.output_suffix = output_suffix\n",
        "       self.append_output_prefix_to_query = append_output_prefix_to_query\n",
        "       self.stop = (output_suffix + input_prefix).strip()\n",
        "       self.description = describe_task\n",
        "\n",
        "   # Adds an example to the model object. Example is an instance of the Example class.\n",
        "   def add_example(self, ex):\n",
        "       self.examples[ex.get_id()] = ex\n",
        "\n",
        "   # Converts all the examples to a particular format to prime the model.\n",
        "   def get_prime_text(self):\n",
        "       return \"\".join(\n",
        "           [self.format_example(ex) for ex in self.examples.values()])\n",
        "\n",
        "   # Creates a query for the API request\n",
        "   def craft_query(self, prompt):\n",
        "       #print(\"description in cratft query\",self.description)\n",
        "       q = self.description+self.get_prime_text(\n",
        "       ) + self.input_prefix + prompt + self.input_suffix\n",
        "\n",
        "       #print(q)\n",
        "       if self.append_output_prefix_to_query:\n",
        "           q = q + self.output_prefix\n",
        "       return q\n",
        "\n",
        "   # Calls the API using the Completion endpoint with the specified values of the parameters\n",
        "   def submit_request(self, prompt):\n",
        "       response = openai.Completion.create(engine=self.engine,\n",
        "                                           prompt=self.craft_query(prompt),\n",
        "                                           max_tokens=self.max_tokens,\n",
        "                                           temperature=self.temperature,\n",
        "                                           top_p=1,\n",
        "                                           n=1,\n",
        "                                           stream=False,\n",
        "                                           stop=self.stop)\n",
        "       return response\n",
        "\n",
        "   # Formats the input output pair with appropriate prefixes and suffixes\n",
        "   def format_example(self, ex):\n",
        "       return self.input_prefix + ex.get_input(\n",
        "       ) + self.input_suffix + self.output_prefix + ex.get_output(\n",
        "       ) + self.output_suffix"
      ],
      "metadata": {
        "id": "gyNuaSwr5EOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **To Do:** Download 'twitter_classification.csv' file from the github and upload to colab"
      ],
      "metadata": {
        "id": "57pYT_u4CEz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1: Study Impact of Different *GPT3* Parameters on Accuracy of Twitter Classification**"
      ],
      "metadata": {
        "id": "FURCcJsJCRMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Load the Twitter data**"
      ],
      "metadata": {
        "id": "hxPZGaZT2ygW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_df= pd.read_csv('twitter_classification.csv')\n",
        "\n",
        "sentiment_df"
      ],
      "metadata": {
        "id": "SK4X0FeZ5shi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checking if Dataset is balanced**"
      ],
      "metadata": {
        "id": "FObjUjF4226w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "dBCovctl5zXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating a GPT3 Object**\n",
        "This was created using GPT3 class from section 3"
      ],
      "metadata": {
        "id": "jFozn0SF2_3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt3_tweet = GPT3(engine=\"davinci\", temperature=0.3, max_tokens=60)"
      ],
      "metadata": {
        "id": "dhaJq5Xm50Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating a training dataset for gpt3**"
      ],
      "metadata": {
        "id": "gAXG_-Z73Uyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a train dataframe to add the example and label for few shot learning \n",
        "\n",
        "no_of_shots = 10\n",
        "train_df=sentiment_df[['label','text']].sample(n=no_of_shots) "
      ],
      "metadata": {
        "id": "qlrJ9Tbo6GQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating a test dataset for gpt3**\n"
      ],
      "metadata": {
        "id": "yIo4DcX932Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Data to Classify Tweet Sentiment and Calculate Accuracy\n",
        "\n",
        "no_of_samples = 30 \n",
        "test_df=sentiment_df[['label','text']].sample(n=no_of_samples) "
      ],
      "metadata": {
        "id": "l0o45TB07901"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating a function for training gpt3**\n",
        "\n",
        "Notice the use of add_example(), add_example() was in section 3 </br>\n",
        "**TODO 2:** Please comment on what this code is doing"
      ],
      "metadata": {
        "id": "6r2eweth4CjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your answer here: ***Enter here***"
      ],
      "metadata": {
        "id": "RtUnj3IxuJS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Training function for GPT3\n",
        "\n",
        "def train_gpt3(train_df):\n",
        "  for i in range(len(train_df)):\n",
        "    example = [train_df.iloc[i]['text'], train_df.iloc[i]['label']]\n",
        "    gpt3_tweet.add_example(Example(example[0],example[1]))"
      ],
      "metadata": {
        "id": "SELG5X_l4RsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating a function for testing gpt3 and returning accuracy**\n",
        "Notice the use of submit_request(), reference section 2. </br>\n",
        "**TODO 3:** Please comment on what is submit_request() doing\n"
      ],
      "metadata": {
        "id": "k2oNzSK9vCOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your answer here: ***Enter here***"
      ],
      "metadata": {
        "id": "YHj3T-ysuzIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Test functions for Calculating Accuracy for Different Parameters \n",
        "def test_gpt3(test_df):\n",
        "  PREDICTED_OUTPUT=[]\n",
        "  IS_ACTUAL_PREDICTED=[]\n",
        "  for i in range(len(test_df)):\n",
        "    prompt=test_df.iloc[i]['text']\n",
        "    output=gpt3_tweet.submit_request(prompt)\n",
        "    PREDICTED_OUTPUT.append((output.choices[0].text).split()[1])\n",
        "  \n",
        "  ## Store Predictions to the test dataframe \n",
        "  test_df['Predicted Sentiment']=PREDICTED_OUTPUT\n",
        "\n",
        "  ## Check if Predicted Sentiment is same as Actual Sentiment\n",
        "  for i in range(len(test_df)):\n",
        "    IS_ACTUAL_PREDICTED.append(test_df.iloc[i]['label']==test_df.iloc[i]['Predicted Sentiment'])\n",
        "\n",
        "  test_df['Actual vs Predicted']=IS_ACTUAL_PREDICTED\n",
        "\n",
        "  ## Accuracy Score\n",
        "  filt = (test_df['Actual vs Predicted']==True)\n",
        "  a=test_df[filt]['Actual vs Predicted'].value_counts()/len(test_df)\n",
        "\n",
        "  ## b is the accuracy\n",
        "  accuracy=a.iloc[0]\n",
        "\n",
        "  return accuracy "
      ],
      "metadata": {
        "id": "0it7IwyT6PrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot the Accuracy Scores for Different Engines**\n",
        "\n",
        "**TODO 4:**\n",
        "1. Enter value for temperature and max_tokens. Temperature is between 0 and 1 and max_tokens can be upto 2048 </br>\n",
        "2. Try removing the timer and test the code. Does it run smoothly? What is the significance of timer? You can try these 2 values 10 and 60 for timer. What were your observations? \n",
        "3. What is the difference between different engines, why are their accuracies different?\n",
        "4. Which engine gives the highest accuracy and why?\n",
        "\n",
        "**Please Note:** This code takes a while to execute due to timer. While your code is running, please work on the code of following tasks\n",
        "\n"
      ],
      "metadata": {
        "id": "Iix4xj-VxWOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your answer here: ***Enter here***"
      ],
      "metadata": {
        "id": "soBPr9n2w1ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Engine Variation\n",
        "engines=['text-davinci-002','text-curie-001','text-babbage-001','text-ada-001','curie','babbage','ada']\n",
        "\n",
        "temperature = None ######### TODO : PROVIDE TEMPARATURES VALUE #########\n",
        "\n",
        "max_tokens = None ######### TODO : PROVIDE MAX_TOKENS VALUE #########\n",
        "\n",
        "accuracy=[]\n",
        "\n",
        "for index in range(len(engines)):\n",
        "\n",
        "  print(\"Engine running: \", engines[index])\n",
        "\n",
        "  gpt3_tweet = GPT3(engine=engines[index], temperature=temperature, max_tokens=max_tokens) \n",
        "  \n",
        "  ## train the model\n",
        "  train_gpt3(train_df)\n",
        "\n",
        "  ## test the model \n",
        "  output=test_gpt3(test_df)\n",
        "\n",
        "  ## store accuracy \n",
        "  accuracy.append(output)\n",
        "\n",
        "  ## sleep to prevent rate limit error \n",
        "  time.sleep(60) ######### TODO : UPDATE SLEEP TIME and CHECK THE RESPONSE IF NECESSARY#########"
      ],
      "metadata": {
        "id": "ERadrpA29JHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(engines, accuracy, width = 0.3)\n",
        " \n",
        "plt.xlabel(\"GPT3 Engines\")\n",
        "plt.ylabel(\"Accuracy Value\")\n",
        "plt.title(\"Accuracy of Classification for different Engines\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ztrEK_L-aXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot the Accuracy Scores for Different Temperatures**\n",
        "\n",
        "**TODO 5:**\n",
        "\n",
        "1. Calculate Accuracy Scores for different Temperature Setting while keeping engines and max_tokens constant \n",
        "\n",
        "2. Plot graph of accuracy with temperature \n",
        "\n",
        "3. Please comment on how accuracy of classification changes with change in temperature\n",
        "\n",
        "**Hint**: You can refer to code from previous part for this section\n",
        "\n",
        "**Please Note:** This code takes a while to execute due to timer. While your code is running, please work on the code of following tasks\n",
        "\n",
        "\n",
        "*Please consider atleast 5 different temperature setting*"
      ],
      "metadata": {
        "id": "OFmUa3k--uPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your observations here: ***Enter here***"
      ],
      "metadata": {
        "id": "6y9gOuyUxMfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write code for Subpart 1 here and store values of accuracy for different temperature setting"
      ],
      "metadata": {
        "id": "8GUwS2iq-v_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write code for Subpart 2 here and plot the graphs "
      ],
      "metadata": {
        "id": "ylFlT2h1BkjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot the Accuracy Scores for Different Tokens**\n",
        "\n",
        "**TODO 6:**\n",
        "\n",
        "1. Calculate Accuracy Scores for different max_tokens setting while keeping engines and temperature constant. \n",
        "\n",
        "2. Plot graph of accuracy with max_token size \n",
        "\n",
        "3. Please comment on how accuracy of classification changes with change in max_tokens\n",
        "\n",
        "**Please Note:** \n",
        "* We recommend that max_tokens value be less than 1700, as some tokens are used by the formating of prompt. \n",
        "\n",
        "* This code takes a while to execute due to timer. While your code is running, please work on the code of following tasks\n",
        "\n",
        "\n",
        "**Hint**: You can refer to code from previous part for this section\n",
        "\n",
        "*Please consider atleast 5 different max_tokens setting*"
      ],
      "metadata": {
        "id": "eUOLNLm3-wqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your observations here: ***Enter here***"
      ],
      "metadata": {
        "id": "fbMUEikDxWkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write code for Subpart 1 here and store values of accuracy for different max_token setting"
      ],
      "metadata": {
        "id": "AaIjAnLKB8X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Write code for Subpart 2 here and plot the graphs "
      ],
      "metadata": {
        "id": "odHjdkqRB_g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optional:** Plot the Accuracy Scores for Different Training Size\n",
        "\n",
        "Please complete task 2 before attempting this"
      ],
      "metadata": {
        "id": "aP9V91E76iSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Generate Title from Abstract of the Research Paper**"
      ],
      "metadata": {
        "id": "WzpwhQEmDnTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Todo 7:** Create object of GPT3 class\n",
        " \n",
        "Important parameters for your gpt3 object:\n",
        "*   Choose an engine of your choice \n",
        "*   Choose a value for your temperature\n",
        "*   describe_task => Give a one liner description of what you want the model to do or leave it blank. \n",
        "*   Recommended number for max_tokens is 150 for this task \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6UwIrXYEAYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt3 = ########## INSERT YOUR CODE HERE ##########"
      ],
      "metadata": {
        "id": "bEhfFE96Gy9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Todo 8:** Import data for this task\n",
        "\n",
        "**File name:** 'Title_Abstract.csv'. </br>\n",
        "**Task:** Upload csv to colab file and read the file below. "
      ],
      "metadata": {
        "id": "beiDBHV5G9u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = ########## INSERT YOUR CODE HERE ##########"
      ],
      "metadata": {
        "id": "emi1ywdIG1yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Zero/Few Shot Learnings and Evaluation for Research Paper Title Creation**\n",
        "\n",
        "In this task, we are experimenting with different number of shots and how accuracy changes with change in tokens \n",
        "\n",
        "**TODO 9**:\n",
        "\n",
        "1. Enter the value of n, where n is index of one of the research papers you want to test on. \n",
        "2. Enter the max_number of shots. \n",
        "    * Question to consider: What is the maximum number of shots we can give for this task? 10? 20? 100? Experiment with code and share the answers with class. \n",
        "    * Based on your answer from previous question, what is the reason of upper limit on the number of shots. \n",
        "3. Use add_example() to train gpt3 with few shot learning\n",
        "4. Send prompt to gpt3 and receive response \n",
        "5. Calculate BLEU Score and compare the reference and candidate. Reference: https://www.nltk.org/api/nltk.translate.bleu_score.html \n",
        "\n",
        "\n",
        "Hint for 3 and 4 subpart: train_gpt3() and test_gpt3() from Task 1 and Section 3"
      ],
      "metadata": {
        "id": "Gn998xmrIFxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your observations here: ***Enter here***"
      ],
      "metadata": {
        "id": "9JhdXGJf4dhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = None ########## INSERT YOUR CODE HERE ##########\n",
        "prompt = data['abstract'][n]\n",
        "actual_title = data['title'][n]"
      ],
      "metadata": {
        "id": "W5qEMcrDUUYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Insert maximum number of shots \n",
        "max_number_of_shots = None ########## INSERT YOUR CODE HERE ##########\n",
        "bleu_scores = []\n",
        "shots=[number_of_shots for number_of_shots in range(max_number_of_shots)]\n",
        "\n",
        "for number_shots in shots:\n",
        "  for index_in_csv in range(number_shots):\n",
        "      # TODO:\n",
        "      # Create example object by using the abstract and title from the csv and add that example to the gpt3 object\n",
        "      ########## INSERT YOUR CODE HERE ##########\n",
        "\n",
        "  \n",
        "  # TODO:\n",
        "  # Submit the prompt using the suitable function from the GPT3 class\n",
        "  response = ########## INSERT YOUR CODE HERE ##########\n",
        "\n",
        "  response_list = response.choices[0].text.lower().split(\" \")\n",
        "\n",
        "  print(\"Number of shots: \", number_shots)\n",
        "  print(response.choices[0].text) \n",
        "\n",
        "  # BLEU Score Calculations\n",
        "  references = [actual_title.split()]\n",
        "  candidate = response_list[1:]\n",
        "\n",
        "  # TODO:\n",
        "  # Calculate the BLEU Score using the references and canditate\n",
        "  \n",
        "  ########## INSERT YOUR CODE HERE ##########\n",
        "\n",
        "  print(\"-------------------------------------------------\")\n",
        "  print(\"-------------------------------------------------\")\n",
        "\n",
        "  gpt3.examples={}"
      ],
      "metadata": {
        "id": "q34-pdnvIFA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot BLEU Scores with Number of Shots**\n",
        "\n",
        "**TODO 10:**\n",
        "1. Enter X and Y in the code. X represents data for x-axis and Y represents data for y-axis. \n",
        "2. Share your learning"
      ],
      "metadata": {
        "id": "x19fqrnD87c1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please include your observations here: ***Enter here***"
      ],
      "metadata": {
        "id": "vJgp8snT4UEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot the graph using bleu_scores vs shots by replacing X,Y with the correct variables in below code\n",
        "X = None ########## INSERT YOUR CODE HERE ##########\n",
        "Y = None ########## INSERT YOUR CODE HERE ##########\n",
        "score_per_shot = pd.DataFrame({'Number_of_Shots' : X, 'BLEU_Score' : Y})\n",
        "score_per_shot.sort_values(by='BLEU_Score', ascending=False)\n",
        "ax = sns.lineplot(data=[score_per_shot['BLEU_Score']], dashes=False, markers=True)\n",
        "ax.set_xticks(range(len(score_per_shot['Number_of_Shots'])))\n",
        "ax.set_xticklabels(score_per_shot['Number_of_Shots'])"
      ],
      "metadata": {
        "id": "o48gYbTNIull"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}